{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import shutil\n",
    "import azureml\n",
    "\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x7fc938157668>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace=ws, name='grab-ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = '../remote_run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./data/devkit/README.txt\n",
      "Uploading ./data/devkit/cars_meta.mat\n",
      "Uploading ./data/devkit/cars_test_annos.mat\n",
      "Uploading ./data/devkit/cars_train_annos.mat\n",
      "Uploading ./data/devkit/eval_train.m\n",
      "Uploading ./data/devkit/train_perfect_preds.txt\n",
      "Uploaded ./data/devkit/eval_train.m, 1 files out of an estimated total of 6\n",
      "Uploaded ./data/devkit/cars_meta.mat, 2 files out of an estimated total of 6\n",
      "Uploaded ./data/devkit/README.txt, 3 files out of an estimated total of 6\n",
      "Uploaded ./data/devkit/train_perfect_preds.txt, 4 files out of an estimated total of 6\n",
      "Uploaded ./data/devkit/cars_test_annos.mat, 5 files out of an estimated total of 6\n",
      "Uploaded ./data/devkit/cars_train_annos.mat, 6 files out of an estimated total of 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_4c13e66da47941e3b34f7f6384a46c56"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./data/devkit', target_path='cars', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.download(target_path='./data', overwrite=False, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "{'creationTime': '2019-06-16T13:01:46.843268+00:00', 'vmPriority': 'Dedicated', 'currentNodeCount': 1, 'allocationStateTransitionTime': '2019-06-16T20:33:03.671000+00:00', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'nodeIdleTimeBeforeScaleDown': 'PT120S', 'maxNodeCount': 2}, 'modifiedTime': '2019-06-16T13:03:07.972287+00:00', 'errors': None, 'vmSize': 'STANDARD_NC6', 'provisioningState': 'Succeeded', 'targetNodeCount': 0, 'allocationState': 'Resizing', 'nodeStateCounts': {'runningNodeCount': 0, 'leavingNodeCount': 1, 'preemptedNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'preparingNodeCount': 0}}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu-cluster AmlCompute Succeeded\n",
      "gpu-cluster AmlCompute Succeeded\n"
     ]
    }
   ],
   "source": [
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, ct.type, ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ws.get_default_datastore().as_mount(),\n",
    "    '--epoch': 100,\n",
    "}\n",
    "\n",
    "est = TensorFlow(source_directory=script_folder,\n",
    "                 script_params=script_params,\n",
    "                 compute_target=compute_target,\n",
    "                 entry_script='./remote_train_resnet.py', \n",
    "                 use_gpu=True,\n",
    "                 pip_packages=['keras', 'matplotlib', 'pandas', 'Pillow', 'pyspark'],\n",
    "                 framework_version='1.13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad736c3f8e6437da7158448f8009d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'send_telemetry': False, 'sdk_version': '1.0.43', 'childWidgetDisplay': 'popupâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-120:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 445, in _handle_results\n",
      "    cache[job]._set(i, obj)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 613, in _set\n",
      "    self._callback(self._value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/azureml/widgets/_userrun/_run_details.py\", line 503, in _update_metrics\n",
      "    self.widget_instance.run_metrics = result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/traitlets.py\", line 585, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/traitlets.py\", line 574, in set\n",
      "    obj._notify_trait(self.name, old_value, new_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/traitlets.py\", line 1139, in _notify_trait\n",
      "    type='change',\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipywidgets/widgets/widget.py\", line 599, in notify_change\n",
      "    self.send_state(key=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipywidgets/widgets/widget.py\", line 484, in send_state\n",
      "    self._send(msg, buffers=buffers)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipywidgets/widgets/widget.py\", line 729, in _send\n",
      "    self.comm.send(data=msg, buffers=buffers)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/comm/comm.py\", line 121, in send\n",
      "    data=data, metadata=metadata, buffers=buffers,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/comm/comm.py\", line 65, in _publish_msg\n",
      "    content = json_clean(dict(data=data, comm_id=self.comm_id, **keys))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/jsonutil.py\", line 191, in json_clean\n",
      "    out[unicode_type(k)] = json_clean(v)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/jsonutil.py\", line 191, in json_clean\n",
      "    out[unicode_type(k)] = json_clean(v)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/jsonutil.py\", line 191, in json_clean\n",
      "    out[unicode_type(k)] = json_clean(v)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/jsonutil.py\", line 177, in json_clean\n",
      "    return [json_clean(x) for x in obj]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/jsonutil.py\", line 177, in <listcomp>\n",
      "    return [json_clean(x) for x in obj]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/jsonutil.py\", line 191, in json_clean\n",
      "    out[unicode_type(k)] = json_clean(v)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/jsonutil.py\", line 177, in json_clean\n",
      "    return [json_clean(x) for x in obj]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/jsonutil.py\", line 177, in <listcomp>\n",
      "    return [json_clean(x) for x in obj]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/jsonutil.py\", line 191, in json_clean\n",
      "    out[unicode_type(k)] = json_clean(v)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/jsonutil.py\", line 177, in json_clean\n",
      "    return [json_clean(x) for x in obj]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/jsonutil.py\", line 177, in <listcomp>\n",
      "    return [json_clean(x) for x in obj]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/jsonutil.py\", line 197, in json_clean\n",
      "    raise ValueError(\"Can't clean for JSON: %r\" % obj)\n",
      "ValueError: Can't clean for JSON: Artifact(data_location=aml://artifactId/ExperimentRun/dcid.grab-ai_1560743650_4fb0b182/Accuracy vs Loss_1560750571.png, filename=Accuracy vs Loss_1560750571.png, metric_type=azureml.v2.image)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "ds.download(target_path='./outputs', prefix='./outputs/', overwrite=False, show_progress=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
